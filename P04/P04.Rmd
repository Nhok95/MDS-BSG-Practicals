---
title: 'Practical 04 SG: Population substructure'
author: "Carlos Moyano & Kleber Reyes"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
editor_options:
  chunk_output_type: console
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
rm(list = ls(all.names = TRUE))
```


```{r load packages, include=FALSE, message=FALSE, warning=FALSE}
library(rstudioapi)
library(stringr)
library(dplyr)
library(genetics)
library(data.table)
library(MASS)
library(corrplot)

set.seed(2209)
current_path <- getActiveDocumentContext()$path 
setwd(dirname(current_path)) 
```

# Population substructure

## 1. Read data.

```{r load_data_question_1}
genotypeData <- fread("Chr21.dat", drop = c(1:6))
dim(genotypeData)
n <- nrow(genotypeData)
max(genotypeData,na.rm=TRUE)
min(genotypeData,na.rm=TRUE)
```

## 2. Compute the Manhattan distance matrix between the individuals (this may take a few minutes) using R function dist. Include a submatrix of dimension 5 by 5 with the distances between the first 5 individuals in your report.

```{r question_2, eval=FALSE}
D <- as.matrix(dist(genotypeData, method = "manhattan"))
```

```{r question_2_store, include=FALSE}
# saveRDS(D, file = "dist_matrix.rds")
D <- readRDS(file = "dist_matrix.rds")
```

```{r question_2_submatrix}
D[1:5,1:5]
```

## 3. The Manhattan distance (also known as the taxicab metric) is identical to the Minkowsky distance with parameter λ = 1. How does the Manhattan distance relate to the allele sharing distance, where the latter is calculated as two minus the *(average)* number of shared alleles *(per locus)*?

The division of the Manhattan distance by the number of polymorphisms gives the **allele-sharing distance**. This is done for the sake of interpretability, because scaling the Manhattan distance in this case results in the following behaviour: pair of individuals two units apart will then differ by two alleles at all loci.

## 4. Apply metric multidimensional scaling using the Manhattan distance matrix to obtain a map of the individuals, and include your map in your report. Do you think the data come from one homogeneous human population? If not, how many subpopulations do you think the data might come from, and how many individuals pertain to each subpopulation?

```{r question_4_1, out.width = "80%", fig.align="center"}
mds.out <- cmdscale(D,eig=TRUE,k=2)
mds.out$GOF
X <- mds.out$points[,1:2]
eqscplot(mds.out$points,type="n")
text(mds.out$point,row.names(genotypeData),cex=.8)
plot(X[,1],X[,2],asp=1,xlab="First principal axis", ylab="Second principal axis")
```

```{r question_4_2, echo=FALSE}
print(paste0("There are ", sum(X[,1]<0), " individuales belonging to the 1st subpopulation (1st PC < 0)"))
print(paste0("There are ", sum(X[,1]>0), " individuales belonging to the 2nd subpopulation (1st PC > 0)"))
```

With k=2, the obtained MDS result clearly shows 2 different human subpopulations. The number of individuals belonging to each subpopulation is around 100 (calculated counting the projected points with values in the 1st PC < 0 and with values > 0).

## 5. Report the first 10 eigenvalues of the solution.

```{r question_5}
mds.out$eig[1:10]
```

## 6. Does a perfect representation of this n × n distance matrix exist, in n or fewer dimensions? Why so or not?

Since MDS is a *dimensionality reduction* technique having the objective of representing a n x n matrix in **less than** n dimensions (if not there's no dimensionality reduction), of course the answer to this question is affirmative. It's always possible to represent the original n x n matrix perfectly by using the same n dimensions and not performing any kind of dimensionality reduction.

## 7. What is the goodness-of-fit of a two-dimensional approximation to your distance matrix? Explain which criterium you have used.

If the criterium used is the scatter plot of the estimated distance vs. the original distance, a satisfactory GoF means visualizing a linear relationship in the plot. This means that the original distance can be linearly recovered from the estimated distance.

## 8. Make a plot of the estimated distances (according to your map of individuals) versus the observed distances. What do you observe? Regress estimated distances on observed distances and report the coefficient of determination of the regression.

```{r question_8_1, out.width = "80%", fig.align="center"}
Dest <- as.matrix(dist(X))
Dobs.vec <- D[lower.tri(D)]
Dest.vec <- Dest[lower.tri(Dest)]
model <- lm(Dest.vec~Dobs.vec)
summary(model)
```

```{r question_8_2, out.width = "80%", fig.align="center", echo=FALSE}
plot(Dobs.vec,Dest.vec,xlab="Observed",ylab="Fitted")
abline(model, col="red", lwd=2)
```
The output obtained depicts two clouds of points that vaguely remind of a straight diagonal line. This lack of definition in the linear relationship between the estimated distance and the original distance indicates that the GoF of our two-dimensional MDS is not very good.

The adjusted R-squared of the regression is 0.843, which is remarkably and indicates that a high percentage of the variability in the estimated distance can be explained using just the original distance as only explanatory variable of a linear regression.

## 9. We now try non-metric multidimensional scaling using the isoMDs instruction. We use a random initial configuration. or the sake of reproducibility, make this random initial configuration with the instructions. Make a plot of the two-dimensional solution. Do the results support that the data come from one homogeneous population? Try some additional runs of isoMDS with different initial configurations, or eventually using the classical metric solution as the initial solution. What do you observe?

```{r question_9_1, out.width = "80%", fig.align="center", message=FALSE, warning=FALSE, results='hide'}
set.seed(12345)
k <- 2
yinit <- scale(matrix(runif(k*n),ncol=k),scale=FALSE)
nmds.out <- isoMDS(D,k=k,y=yinit)
s <- nmds.out$stress
Z <- nmds.out$points[,1:2]
plot(Z[,1],Z[,2],asp=1)
```

```{r question_9_1_s}
s
```
In the plot of the non-metric MDS two-dimensional result no more than a single homogeneous population is identifiable. When `isoMDS` is run with different initial configurations (using different seeds/random states), in some cases the circular shape is maintained, but the points seem to be different at first glance, and in others,  instead of a single circular point cloud, there are 2 point clouds of different shape (see the example below).

```{r question_9_2, out.width = "80%", fig.align="center", message=FALSE, warning=FALSE, results='hide'}
set.seed(105)
k <- 2
yinit <- scale(matrix(runif(k*n),ncol=k),scale=FALSE)
nmds.out <- isoMDS(D,k=k,y=yinit)
s <- nmds.out$stress; s
Z <- nmds.out$points[,1:2]
plot(Z[,1],Z[,2],asp=1)
```

```{r question_9_2_s}
s
```
With the classical metrical solution (depicted below), the result is exactly the same as the one obtained in question 4.

```{r question_9_3, out.width = "80%", fig.align="center", message=FALSE, warning=FALSE, results='hide'}
set.seed(2209) # same seed as at the beginning
k <- 2
nmds.out <- isoMDS(D,k=k) # if y is None, classical solution
s <- nmds.out$stress; s
Z <- nmds.out$points[,1:2]
plot(Z[,1],Z[,2],asp=1)
```

```{r question_9_3_s}
s
```

## 10. Set the seed of the random number generator to 123. Then run isoMDS a hundred times, each time using a different random initial configuration using the instructions above. Save the final stress-value and the coordinates of each run. Report the stress of the best run, and plot the corresponding map.

We have used the runif function in order to have a different initial configuration in each iteration.

```{r question_10_1, message=FALSE, warning=FALSE, results='hide'}
set.seed(123)
stress.list = c()
coordinates.list = c()
for(i in 1:100){
  init <- scale(matrix(runif(2*n),ncol=2), scale=FALSE)
  nmds.out <- isoMDS(D,k=2,y=init,trace=FALSE)
  stress.list[i] = nmds.out$stress
  coordinates.list[[i]] = nmds.out$points
}
```

```{r question_10_2, include=FALSE}
#saveRDS(stress.list, file = "stress.rds")
#saveRDS(coordinates.list, file = "coords.rds")
stress.list <- readRDS(file = "stress.rds")
coordinates.list <- readRDS(file = "coords.rds")
```

Our best run is the one with the lowest stress value, once we get the corresponding map we can plot it.

```{r question_10_3, out.width = "80%", fig.align="center", echo=FALSE}
min(stress.list)
Z <- coordinates.list[[which.min(stress.list)]][,1:2]
plot(Z[,1], Z[,2])
```

The minimum stress value is 11.40856 that is really close to the obtained with the previous seed 105. Once again, we have 2 point clouds. 

## 11. Make again a plot of the estimated distances (according to your map of individuals of the best run) versus the observed distances, now for the two-dimensional solution of non-metric MDS. Regress estimated distances on observed distances and report the coefficient of determination of the regression.

```{r question_11_1}
Dest.best <- as.matrix(dist(Z))
Dest.best.vec <- Dest.best[lower.tri(Dest.best)]
model2 <- lm(Dest.best.vec~Dobs.vec)
summary(model2)$r.squared
```

```{r question_11_2, out.width = "80%", fig.align="center", echo=FALSE}
plot(Dobs.vec, Dest.best.vec, xlab="Observed", ylab="Fitted")
abline(model2, col="red", lwd=2)
```

This time we can notice a better separation between the 2 point clouds than the obtained in question 8.

The adjusted R-squared of the regression is 0.869, more or less the same as the previous calculation.

## 12. Compute the stress for a 1, 2, 3, 4, . . . , n-dimensional solution, always using the classical MDS solution as an initial configuration. How many dimensions are necessary to obtain a good representation with a stress below 5? Make a plot of the stress against the number of dimensions

```{r question_12_1}
set.seed(123)
stress.list2 <- c()
stress.value = 6
k = 1
while(stress.value > 5) {
  init <- scale(matrix(runif(k*n),ncol=k),scale=FALSE)
  nmds.out <- isoMDS(D,k=k,y=init, maxit=100, trace=FALSE)
  stress.value = nmds.out$stress
  stress.list2[k] = stress.value
  k = k +1
}
k-1
stress.value
```

We need 20 dimensions to obtain a stress value below 5.

```{r question_12_2, include=FALSE}
#saveRDS(stress.list2, file = "stress2.rds")
#saveRDS(stress.value, file = "stress_value.rds")
#saveRDS(k, file = "k.rds")
```

```{r question_12_3, include=FALSE}
stress.list2 <- readRDS(file = "stress2.rds")
stress.value <- readRDS(file = "stress_value.rds")
k <- readRDS(file = "k.rds")
```

```{r question_12_4, out.width = "80%", fig.align="center"}
plot(1:length(stress.list2), stress.list2,type="b",xlab="k", main="Stress as number of dimensions")
abline(h=5, col="blue")
```

In this plot we can see the decreasing trend of stress as the dimensions increase.

## 13. Compute the correlation matrix between the first two dimensions of a metric MDS and the two-dimensional solution of your best non-metric MDS. Make a scatterplot matrix of the 4 variables. Comment on your findings.

```{r question_13, out.width = "80%", fig.align="center"}
matrix = cbind(X,Z)
colnames(matrix) = c("MDS.1","MDS.2","NMDS.1","NMDS.2")
cor.mds = round(cor(matrix, method="spearman"), 2)
corrplot(cor.mds, method = 'number', type = 'lower', bg = "lightgray")
pairs(matrix)
```

With the info obtained from the correlation matrix and the pairs plot, we can affirm that MDS.1 and NMDS.1 are highly correlated (correlation is almost 1), but the same DOES NOT HAPPEN with MDS.2 and NMDS.2 (correlation is 0.01). This makes sense *partly* since we expect that both techniques find more or less the same solution (the same dimensions) as part of the dimensionality reduction process. It is remarkable to point out that there's a lot of positive correlation between NMDS.2 and NMDS.1 (correlation is 0.62), while this does not happen between MDS.1 and MDS.2. This behaviour is not desired since we would like to obtain *independent* dimensions, and this seems not to be the case in the output of the best non-metric MDS.
